{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to sys.path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from methods.ipsw import estimate_sampling_scores, estimate_ate_ipsw\n",
    "from methods.ipsw import IPSWEstimator\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(n=100000, seed=123):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Covariates\n",
    "    X1 = rng.normal(0, 1, size=n)\n",
    "    X2 = rng.binomial(1, 0.5, size=n)\n",
    "\n",
    "    # Sampling mechanism\n",
    "    # Trial oversamples high X1 and high X2 individuals\n",
    "    logits_S = -0.3 + 1.0 * X1 + 1.0 * X2\n",
    "    pS = 1 / (1 + np.exp(-logits_S))\n",
    "    S = rng.binomial(1, pS)\n",
    "\n",
    "    # Randomized treatment in trial only\n",
    "    T = np.zeros(n)\n",
    "    mask_trial = S == 1\n",
    "    T[mask_trial] = rng.binomial(1, 0.5, mask_trial.sum())\n",
    "\n",
    "    # Heterogeneous treatment effect:\n",
    "    # tau_i = 2 + 3 * X1\n",
    "    tau_i = 2 + 3 * X1\n",
    "\n",
    "    # Outcome model\n",
    "    beta1, beta2 = 1.0, -1.0\n",
    "    eps = rng.normal(0, 1, size=n)\n",
    "\n",
    "    Y = tau_i * T + beta1 * X1 + beta2 * X2 + eps\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"X1\": X1,\n",
    "        \"X2\": X2,\n",
    "        \"S\": S,\n",
    "        \"T\": T,\n",
    "        \"Y\": Y,\n",
    "        \"tau_true\": tau_i,\n",
    "        \"pS_true\": pS\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1  X2  S    T         Y  tau_true   pS_true\n",
      "0  0.304717   1  1  1.0  0.854248  2.914151  0.731985\n",
      "1 -1.039984   1  0  0.0 -1.686244 -1.119952  0.415813\n",
      "2  0.750451   0  1  1.0  5.555570  4.251354  0.610747\n",
      "3  0.940565   0  1  1.0  5.099770  4.821694  0.654881\n",
      "4 -1.951035   0  0  0.0 -0.290278 -3.853106  0.095260\n"
     ]
    }
   ],
   "source": [
    "df = simulate_data(n=8000, seed=42)\n",
    "print(df.head())\n",
    "\n",
    "# 1. Design matrices / vectors\n",
    "X = df[[\"X1\", \"X2\"]]          # covariates used in sampling model\n",
    "s = df[\"S\"].to_numpy()        # sample indicator (1 = trial, 0 = target)\n",
    "a = df[\"T\"].to_numpy()        # treatment\n",
    "y = df[\"Y\"].to_numpy()        # outcome\n",
    "\n",
    "# True ATE in the target population (S = 0)\n",
    "ATE_target_true = df.loc[df[\"S\"] == 0, \"tau_true\"].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIPSW (logit, XGB) ATE: 0.656005755717767\n",
      "SE: 0.19902598040204234\n",
      "95% CI: (0.2456615817648171, 1.0459322244102058)\n"
     ]
    }
   ],
   "source": [
    "# methods/bootstrap_utils.py\n",
    "\n",
    "# 2. Estimate P(S = 1 | X)\n",
    "ps_hat, model = estimate_sampling_scores(X, s)\n",
    "\n",
    "# 3. Use IPSW to estimate ATE in the *target* population\n",
    "# For generalizing to S=0, inverse-odds weights are standard:\n",
    "result = estimate_ate_ipsw(\n",
    "    y=y,\n",
    "    a=a,\n",
    "    s=s,\n",
    "    ps=ps_hat,\n",
    "    weight_type = \"inverse_odds\",   # key for generalizability to S=0\n",
    "    stabilized=True,\n",
    "    clip=(0.01, 50),              # optional, to tame extreme weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_xgb = IPSWEstimator(\n",
    "    model=XGBClassifier(\n",
    "        max_depth=3,\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"logloss\",\n",
    "    ),\n",
    "    weight_type=\"inverse_odds\",   # generalizability to S = 0\n",
    "    stabilized=True,\n",
    "    clip=(0.01, 50),\n",
    ")\n",
    "\n",
    "est_xgb.fit(X, s)\n",
    "res_xgb = est_xgb.estimate(y, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_rf = IPSWEstimator(\n",
    "    model=RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=6,\n",
    "    ),\n",
    "    weight_type=\"inverse_odds\",  # generalizability to S = 0\n",
    "    stabilized=True,\n",
    ")\n",
    "\n",
    "est_rf.fit(X, s)\n",
    "res_rf = est_rf.estimate(y, a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE IPSW ATE (target): 0.6804878754636353\n",
      "XGB IPSW ATE (target): 0.6301638712287438\n",
      "RF IPSW ATE (target): 0.9923600517584062\n",
      "IPSW ATE estimate LR (target): 0.656005755717767\n"
     ]
    }
   ],
   "source": [
    "print(\"TRUE IPSW ATE (target):\", ATE_target_true)\n",
    "print(\"XGB IPSW ATE (target):\", res_xgb.ate)\n",
    "print(\"RF IPSW ATE (target):\", res_rf.ate)\n",
    "print(\"IPSW ATE estimate LR (target):\", result.ate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented IPSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIPSW ATE: 0.6572131063034092\n",
      "AIPSW ATE: 0.6363389715675143\n",
      "AIPSW ATE (XGB outcome): 0.6413754454949849\n"
     ]
    }
   ],
   "source": [
    "ps, _ = estimate_sampling_scores(X, s)\n",
    "\n",
    "result = estimate_ate_aipsw(\n",
    "    y=y,\n",
    "    a=a,\n",
    "    s=s,\n",
    "    X=X,\n",
    "    ps=ps,                    # or let it estimate inside\n",
    "    weight_type=\"inverse_odds\",\n",
    "    stabilized=True,\n",
    "    clip=(0.1, 10.0),\n",
    "    target=\"nontrial\",\n",
    ")\n",
    "\n",
    "print(\"AIPSW ATE:\", result.ate)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from methods.aipsw import estimate_ate_aipsw\n",
    "\n",
    "rf_outcome = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "result = estimate_ate_aipsw(\n",
    "    y=y,\n",
    "    a=a,\n",
    "    s=s,\n",
    "    X=X,\n",
    "    sampling_model=None,              # maybe still logistic for sampling\n",
    "    sampling_model_kwargs={},\n",
    "    outcome_model=rf_outcome,         # <--- your flexible regression model\n",
    "    outcome_model_kwargs={},          # ignored because model is provided\n",
    "    weight_type=\"inverse_odds\",\n",
    "    stabilized=True,\n",
    "    clip=(0.1, 10.0),\n",
    "    target=\"nontrial\",\n",
    ")\n",
    "\n",
    "print(\"AIPSW ATE:\", result.ate)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from methods.aipsw import estimate_ate_aipsw\n",
    "\n",
    "xgb_outcome = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "result = estimate_ate_aipsw(\n",
    "    y=y,\n",
    "    a=a,\n",
    "    s=s,\n",
    "    X=X,\n",
    "    sampling_model=None,          # still logistic for sampling by default\n",
    "    sampling_model_kwargs={},\n",
    "    outcome_model=xgb_outcome,    # <-- XGBoost outcome model\n",
    "    outcome_model_kwargs={},      # ignored because you passed a model\n",
    "    weight_type=\"inverse_odds\",\n",
    "    stabilized=True,\n",
    "    clip=(0.1, 10.0),\n",
    "    target=\"nontrial\",\n",
    ")\n",
    "\n",
    "print(\"AIPSW ATE (XGB outcome):\", result.ate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified ATE: 0.9602307004504487\n",
      "Stratum-specific ATEs: [-1.53538298  0.75035567  2.22220991  3.40606334  5.79762477]\n"
     ]
    }
   ],
   "source": [
    "from methods.stratification import estimate_ate_stratified\n",
    "\n",
    "result = estimate_ate_stratified(\n",
    "    Y=df[\"Y\"].values,\n",
    "    T=df[\"T\"].values,\n",
    "    S=df[\"S\"].values,\n",
    "    X=df[[\"X1\", \"X2\"]],\n",
    "    n_strata=5,\n",
    "    target=\"nontrial\",\n",
    ")\n",
    "\n",
    "print(\"Stratified ATE:\", result.ate)\n",
    "print(\"Stratum-specific ATEs:\", result.stratum_ates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximiannecastaneda/Desktop/Extrapolation/.venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [16:19:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified ATE: 0.8299342430824019\n",
      "Stratum weights (target pop): [0.35310269 0.24766612 0.19824272 0.1394838  0.06150467]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from methods.stratification import StratifiedGeneralizabilityEstimator\n",
    "\n",
    "xgb_sampler = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    ")\n",
    "\n",
    "est = StratifiedGeneralizabilityEstimator(\n",
    "    n_strata=5,\n",
    "    target=\"nontrial\",\n",
    "    sampling_model=xgb_sampler,\n",
    ")\n",
    "\n",
    "# Note: capital S in the argument name\n",
    "est.fit(X=df[[\"X1\", \"X2\"]], S=df[\"S\"].values)\n",
    "\n",
    "# Use Y, T, S and capitalized argument names\n",
    "result = est.estimate_ate(\n",
    "    Y=df[\"Y\"].values,\n",
    "    T=df[\"T\"].values,   # or df[\"A\"].values if your column is still named A\n",
    "    S=df[\"S\"].values,\n",
    ")\n",
    "\n",
    "print(\"Stratified ATE:\", result.ate)\n",
    "print(\"Stratum weights (target pop):\", result.stratum_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G-formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome-model ATE: 0.6467929949439102\n",
      "μ1: -0.16718033678216815 μ0: -0.8139733317260783\n"
     ]
    }
   ],
   "source": [
    "from methods.outcomeM import (\n",
    "    OutcomeModelGeneralizabilityEstimator,\n",
    "    estimate_ate_outcome,\n",
    ")\n",
    "\n",
    "# One-shot function\n",
    "result = estimate_ate_outcome(\n",
    "    Y=df[\"Y\"].values,\n",
    "    T=df[\"T\"].values,\n",
    "    S=df[\"S\"].values,\n",
    "    X=df[[\"X1\", \"X2\"]],\n",
    "    target=\"nontrial\",\n",
    ")\n",
    "\n",
    "print(\"Outcome-model ATE:\", result.ate)\n",
    "print(\"μ1:\", result.ate_treated, \"μ0:\", result.ate_control)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome-model ATE (XGB): 0.6484324038028717\n",
      "μ1: -0.14614489674568176 μ0: -0.7945773005485535\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from methods.outcomeM import OutcomeModelGeneralizabilityEstimator\n",
    "\n",
    "xgb_outcome = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "est = OutcomeModelGeneralizabilityEstimator(\n",
    "    target=\"nontrial\",\n",
    "    outcome_model=xgb_outcome,\n",
    ")\n",
    "\n",
    "est.fit(\n",
    "    X=df[[\"X1\", \"X2\"]],\n",
    "    Y=df[\"Y\"].values,\n",
    "    T=df[\"T\"].values,\n",
    "    S=df[\"S\"].values,\n",
    ")\n",
    "\n",
    "result = est.estimate_ate()\n",
    "\n",
    "print(\"Outcome-model ATE (XGB):\", result.ate)\n",
    "print(\"μ1:\", result.ate_treated, \"μ0:\", result.ate_control)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calbriation Weighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration-weighted ATE: 0.6628224815065443\n"
     ]
    }
   ],
   "source": [
    "from methods.calibration import estimate_ate_calibration\n",
    "\n",
    "result = estimate_ate_calibration(\n",
    "    Y=df[\"Y\"].values,\n",
    "    T=df[\"T\"].values,\n",
    "    S=df[\"S\"].values,\n",
    "    X=df[[\"X1\", \"X2\"]],\n",
    "    target=\"nontrial\",\n",
    ")\n",
    "\n",
    "print(\"Calibration-weighted ATE:\", result.ate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Calbriation Weighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Calibration ATE: 0.6686458435544305\n"
     ]
    }
   ],
   "source": [
    "from methods.acalibration import estimate_ate_calibration_augmented\n",
    "\n",
    "result = estimate_ate_calibration_augmented(\n",
    "    Y=df[\"Y\"].values,\n",
    "    T=df[\"T\"].values,\n",
    "    S=df[\"S\"].values,\n",
    "    X=df[[\"X1\", \"X2\"]],\n",
    "    target=\"nontrial\",\n",
    ")\n",
    "\n",
    "print(\"Augmented Calibration ATE:\", result.ate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Calibration ATE (XGB): 0.6330386800608776\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from methods.acalibration import AugmentedCalibrationGeneralizabilityEstimator\n",
    "\n",
    "xgb_outcome = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "est = AugmentedCalibrationGeneralizabilityEstimator(\n",
    "    target=\"nontrial\",\n",
    "    outcome_model=xgb_outcome,\n",
    ")\n",
    "\n",
    "est.fit(\n",
    "    X=df[[\"X1\", \"X2\"]],\n",
    "    Y=df[\"Y\"].values,\n",
    "    T=df[\"T\"].values,\n",
    "    S=df[\"S\"].values,\n",
    ")\n",
    "\n",
    "result = est.estimate_ate()\n",
    "\n",
    "print(\"Augmented Calibration ATE (XGB):\", result.ate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
